{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Model\n",
    "\n",
    "**Authors:** Christopher Sun, Jai Sharma, Milind Maiti\n",
    "\n",
    "**Date:** 2022.06.16\n",
    "\n",
    "**Description:** This module concerns the elevation data for the satellite images (from the IEEE dataport). The tasks here include:\n",
    "\n",
    "1. Filter tif file elevation masks based on good and bad data.\n",
    "2. Define a U-Net Deep Learning framework for predicting the pixelwise elevation of an RGB satellite image.\n",
    "3. Interpolate the bad data discovered in number (1) using the U-Net Deep Learning model trained in number (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-03T01:34:12.551868Z",
     "iopub.status.busy": "2022-03-03T01:34:12.551305Z",
     "iopub.status.idle": "2022-03-03T01:34:12.603452Z",
     "shell.execute_reply": "2022-03-03T01:34:12.602745Z",
     "shell.execute_reply.started": "2022-03-03T01:34:12.551771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import figure\n",
    "from mpl_toolkits import mplot3d\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks, Sequential, Input, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import scipy\n",
    "import pickle\n",
    "import gc \n",
    "from IPython.display import display\n",
    "\n",
    "# Print Confirmation\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Determine Good Data vs Bad Data\n",
    "\n",
    "The following is the number of images from each location:\n",
    "\n",
    "**San Fernando**: 2325\n",
    "\n",
    "**Atlanta**: 705\n",
    "\n",
    "**Jacksonville**: 1098\n",
    "\n",
    "**Omaha**: 1796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T02:03:05.729129Z",
     "iopub.status.busy": "2022-03-03T02:03:05.728811Z",
     "iopub.status.idle": "2022-03-03T02:03:08.608483Z",
     "shell.execute_reply": "2022-03-03T02:03:08.607445Z",
     "shell.execute_reply.started": "2022-03-03T02:03:05.729096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "j2ks = pickle.load(open(\"/kaggle/input/geocentric-pose-analysis-of-satellite-imagery/j2k_imgs.dat\", \"rb\"))\n",
    "tifs = pickle.load(open(\"/kaggle/input/geocentric-pose-analysis-of-satellite-imagery/tif_imgs.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T02:04:00.448412Z",
     "iopub.status.busy": "2022-03-03T02:04:00.44812Z",
     "iopub.status.idle": "2022-03-03T02:04:01.130892Z",
     "shell.execute_reply": "2022-03-03T02:04:01.129903Z",
     "shell.execute_reply.started": "2022-03-03T02:04:00.448381Z"
    }
   },
   "outputs": [],
   "source": [
    "# San Fernando\n",
    "sf_threshold = 3000\n",
    "for i in range(2325):\n",
    "    if np.max(tifs[i]) < 65535:\n",
    "        tifs[i][(tifs[i] >= sf_threshold) & (tifs[i] < 65535)] = np.median(tifs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T02:04:01.133079Z",
     "iopub.status.busy": "2022-03-03T02:04:01.1327Z",
     "iopub.status.idle": "2022-03-03T02:04:01.418247Z",
     "shell.execute_reply": "2022-03-03T02:04:01.417238Z",
     "shell.execute_reply.started": "2022-03-03T02:04:01.133036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Atlanta\n",
    "atl_threshold = 4000\n",
    "max_num = 100 # Max number of pixels above 4000 to be considered an outlier\n",
    "              # Any tifs with more than 100 pixels will be considered good data\n",
    "for i in range(2325, 3030):\n",
    "    if (np.sum(tifs[i] >= atl_threshold) < max_num) and (np.max(tifs[i] < 65535)):\n",
    "        tifs[i][(tifs[i] >= atl_threshold) & (tifs[i] < 65535)] = np.median(tifs[i])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T02:04:01.497765Z",
     "iopub.status.busy": "2022-03-03T02:04:01.497509Z",
     "iopub.status.idle": "2022-03-03T02:04:04.233775Z",
     "shell.execute_reply": "2022-03-03T02:04:04.232747Z",
     "shell.execute_reply.started": "2022-03-03T02:04:01.497721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "threshold = 10000\n",
    "for i in range(tifs.shape[0]):\n",
    "    if (np.sum(tifs[i] >= threshold) < 50) and (np.max(tifs[i] < 65535)):\n",
    "        tifs[i][(tifs[i] >= threshold) & (tifs[i] < 65535)] = np.median(tifs[i])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for i in range(tifs.shape[0]):\n",
    "    tifs[i][(tifs[i] >= 20000) & (tifs[i] < 65535)] = np.median(tifs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T07:26:13.852066Z",
     "iopub.status.busy": "2022-03-02T07:26:13.851799Z",
     "iopub.status.idle": "2022-03-02T07:26:14.665872Z",
     "shell.execute_reply": "2022-03-02T07:26:14.665061Z",
     "shell.execute_reply.started": "2022-03-02T07:26:13.852026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Images without NaNs (good data)\n",
    "idxs_keep = np.argwhere(np.sum(np.sum(tifs==65535, axis=1), axis=1) == 0).reshape(-1)\n",
    "tifs = tifs[idxs_keep]\n",
    "j2ks = j2ks[idxs_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T01:38:11.192882Z",
     "iopub.status.busy": "2022-03-01T01:38:11.192579Z",
     "iopub.status.idle": "2022-03-01T01:38:12.0155Z",
     "shell.execute_reply": "2022-03-01T01:38:12.014889Z",
     "shell.execute_reply.started": "2022-03-01T01:38:11.192825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize distribution of tif values\n",
    "tifs_flattened = tifs.flatten()\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(tifs_flattened[(tifs_flattened >= 10000) & (tifs_flattened < 65535)])\n",
    "plt.xlabel(\"Pixel Elevation (cm)\", fontsize=12)\n",
    "plt.ylabel(\"No. of Pixels\", fontsize=12)\n",
    "plt.title(\"Outlier Analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T01:45:07.442516Z",
     "iopub.status.busy": "2022-03-01T01:45:07.442197Z",
     "iopub.status.idle": "2022-03-01T01:45:08.127267Z",
     "shell.execute_reply": "2022-03-01T01:45:08.126388Z",
     "shell.execute_reply.started": "2022-03-01T01:45:07.442483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the maximum of each example with the minimum if this value is over the threshold\n",
    "# threshold = 10000\n",
    "# for i in range(tifs.shape[0]):\n",
    "#     if (np.sum(tifs[i] >= threshold) < 10) and (np.max(tifs[i] >= threshold)):\n",
    "#         tifs[i][tifs[i] >= threshold] = np.median(tifs[i])\n",
    "#     else:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T01:42:57.266128Z",
     "iopub.status.busy": "2022-03-03T01:42:57.265821Z",
     "iopub.status.idle": "2022-03-03T01:42:57.859146Z",
     "shell.execute_reply": "2022-03-03T01:42:57.858121Z",
     "shell.execute_reply.started": "2022-03-03T01:42:57.266095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter based on good data\n",
    "# idxs_keep = np.argwhere(np.sum(np.sum(tifs==65535, axis=1), axis=1) != 0).reshape(-1)\n",
    "# tifs = tifs[idxs_keep]\n",
    "# j2ks = j2ks[idxs_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T06:38:15.50128Z",
     "iopub.status.busy": "2022-02-19T06:38:15.500487Z",
     "iopub.status.idle": "2022-02-19T06:38:15.937295Z",
     "shell.execute_reply": "2022-02-19T06:38:15.936478Z",
     "shell.execute_reply.started": "2022-02-19T06:38:15.50123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the number of NaN values for each example and display a corresponding histogram\n",
    "num_nans = np.sum(np.sum(tifs == 65535, axis=1), axis=1)\n",
    "plt.hist(num_nans[num_nans!=0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T01:18:15.157758Z",
     "iopub.status.busy": "2022-03-01T01:18:15.157295Z",
     "iopub.status.idle": "2022-03-01T01:18:15.940271Z",
     "shell.execute_reply": "2022-03-01T01:18:15.939615Z",
     "shell.execute_reply.started": "2022-03-01T01:18:15.157721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display several examples of RGB images and their corresponding tif files with missing data\n",
    "fig, axs = plt.subplots(1,4, figsize=(14,7))\n",
    "axs[0].imshow(j2ks[72])\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title(\"RGB Image\")\n",
    "axs[1].imshow(tifs[72])\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].set_title(\"Elevation Mask\")\n",
    "axs[2].imshow(j2ks[59])\n",
    "axs[2].axis(\"off\")\n",
    "axs[2].set_title(\"RGB Image\")\n",
    "axs[3].imshow(tifs[59])\n",
    "axs[3].axis(\"off\")\n",
    "axs[3].set_title(\"Elevation Mask\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T00:36:35.234079Z",
     "iopub.status.busy": "2022-02-26T00:36:35.23362Z",
     "iopub.status.idle": "2022-02-26T00:36:36.438066Z",
     "shell.execute_reply": "2022-02-26T00:36:36.437336Z",
     "shell.execute_reply.started": "2022-02-26T00:36:35.234042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the median pixel value for each image\n",
    "tif_medians = np.median(tifs, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T01:58:55.575248Z",
     "iopub.status.busy": "2022-02-18T01:58:55.574979Z",
     "iopub.status.idle": "2022-02-18T01:58:56.174051Z",
     "shell.execute_reply": "2022-02-18T01:58:56.173336Z",
     "shell.execute_reply.started": "2022-02-18T01:58:55.575219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the number of tifs with median of either min or max value\n",
    "# These could be examples of bad data\n",
    "count = 0\n",
    "for i in range(tif_medians.shape[0]):\n",
    "    min_value = np.min(tifs[i])\n",
    "    max_value = np.max(tifs[i])\n",
    "    if (tif_medians[i] == min_value) or (tif_medians[i] == max_value):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T01:28:03.138254Z",
     "iopub.status.busy": "2022-02-24T01:28:03.138001Z",
     "iopub.status.idle": "2022-02-24T01:28:03.606619Z",
     "shell.execute_reply": "2022-02-24T01:28:03.605912Z",
     "shell.execute_reply.started": "2022-02-24T01:28:03.138226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting elevation pixels into two classes based on if the median value is equal to \n",
    "# either the minimum or maximum value in the image. If the tif is kept, then it is \n",
    "# turned into a binary coloring based on the value of the median. \n",
    "for i in range(tif_medians.shape[0]):\n",
    "    if tif_medians[i] == np.min(tifs[i]):\n",
    "        tifs[i] = (tifs[i] != np.min(tifs[i]))\n",
    "    elif tif_medians[i] == np.max(tifs[i]):\n",
    "        tifs[i] = (tifs[i] == np.max(tifs[i]))\n",
    "    else:\n",
    "        tifs[i] = tifs[i] >= tif_medians[i]\n",
    "        \n",
    "tifs = tifs.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T01:44:41.985161Z",
     "iopub.status.busy": "2022-02-24T01:44:41.984907Z",
     "iopub.status.idle": "2022-02-24T01:44:42.404898Z",
     "shell.execute_reply": "2022-02-24T01:44:42.40427Z",
     "shell.execute_reply.started": "2022-02-24T01:44:41.985132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show a random RGB image and the corresponding tif file.\n",
    "# At this point, all tif files should be good data.\n",
    "q = int(np.random.uniform(tifs.shape[0]))\n",
    "print(q)\n",
    "plt.imshow(j2ks[q])\n",
    "plt.show()\n",
    "plt.imshow(tifs[q])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T01:05:12.281283Z",
     "iopub.status.busy": "2022-02-26T01:05:12.281013Z",
     "iopub.status.idle": "2022-02-26T01:05:12.43857Z",
     "shell.execute_reply": "2022-02-26T01:05:12.437846Z",
     "shell.execute_reply.started": "2022-02-26T01:05:12.281252Z"
    }
   },
   "outputs": [],
   "source": [
    "tifs_flattened = tifs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T01:43:02.489916Z",
     "iopub.status.busy": "2022-03-03T01:43:02.489572Z",
     "iopub.status.idle": "2022-03-03T01:43:02.521137Z",
     "shell.execute_reply": "2022-03-03T01:43:02.519763Z",
     "shell.execute_reply.started": "2022-03-03T01:43:02.489884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "def build_model():\n",
    "    inputs = Input(shape=(256, 256, 3))\n",
    "    conv1 = Conv2D(32, (5, 5), padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation(\"relu\")(conv1)\n",
    "    conv1 = Conv2D(32, (5, 5), padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation(\"relu\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, (5, 5), padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation(\"relu\")(conv2)\n",
    "    conv2 = Conv2D(64, (5, 5), padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation(\"relu\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (5, 5), padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation(\"relu\")(conv3)\n",
    "    conv3 = Conv2D(128, (5, 5), padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation(\"relu\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (5, 5), padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation(\"relu\")(conv4)\n",
    "    conv4 = Conv2D(256, (5, 5), padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation(\"relu\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (5, 5), padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation(\"relu\")(conv5)\n",
    "    conv5 = Conv2D(512, (5, 5), padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation(\"relu\")(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (5, 5), padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation(\"relu\")(conv6)\n",
    "    conv6 = Conv2D(256, (5, 5), padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation(\"relu\")(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (5, 5), padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation(\"relu\")(conv7)\n",
    "    conv7 = Conv2D(128, (5, 5), padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation(\"relu\")(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (5, 5), padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation(\"relu\")(conv8)\n",
    "    conv8 = Conv2D(64, (5, 5), padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation(\"relu\")(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (5, 5), padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation(\"relu\")(conv9)\n",
    "    conv9 = Conv2D(16, (5, 5), padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation(\"relu\")(conv9)\n",
    "  \n",
    "    outputs = Conv2D(1, (1, 1), activation=\"relu\")(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T01:43:03.280133Z",
     "iopub.status.busy": "2022-03-03T01:43:03.279562Z",
     "iopub.status.idle": "2022-03-03T01:43:06.680311Z",
     "shell.execute_reply": "2022-03-03T01:43:06.679354Z",
     "shell.execute_reply.started": "2022-03-03T01:43:03.280099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and compile the model\n",
    "model = build_model()\n",
    "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T01:43:06.682481Z",
     "iopub.status.busy": "2022-03-03T01:43:06.682212Z",
     "iopub.status.idle": "2022-03-03T01:43:06.738266Z",
     "shell.execute_reply": "2022-03-03T01:43:06.737357Z",
     "shell.execute_reply.started": "2022-03-03T01:43:06.682448Z"
    }
   },
   "outputs": [],
   "source": [
    "# View the model architecture summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T00:37:57.070006Z",
     "iopub.status.busy": "2022-03-02T00:37:57.069745Z",
     "iopub.status.idle": "2022-03-02T00:37:57.382409Z",
     "shell.execute_reply": "2022-03-02T00:37:57.381661Z",
     "shell.execute_reply.started": "2022-03-02T00:37:57.069978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the train and validation sets\n",
    "X_t, X_v, y_t, y_v = train_test_split(j2ks, tifs, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T02:46:04.394778Z",
     "iopub.status.busy": "2022-03-02T02:46:04.394479Z",
     "iopub.status.idle": "2022-03-02T04:03:49.102205Z",
     "shell.execute_reply": "2022-03-02T04:03:49.101101Z",
     "shell.execute_reply.started": "2022-03-02T02:46:04.394745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_t, y_t, validation_data=(X_v, y_v), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learning curves\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.show()\n",
    "plt.plot(history.history[\"mse\"])\n",
    "plt.plot(history.history[\"val_mse\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualize Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T07:08:49.641026Z",
     "iopub.status.busy": "2022-03-02T07:08:49.640542Z",
     "iopub.status.idle": "2022-03-02T07:08:51.036979Z",
     "shell.execute_reply": "2022-03-02T07:08:51.0356Z",
     "shell.execute_reply.started": "2022-03-02T07:08:49.640986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the accuracy of the U-Net model\n",
    "tifs_test = model.predict(j2ks[idxs_keep]).reshape(j2ks[idxs_keep].shape[0], 256, 256)\n",
    "fig, ax = plt.subplots(5,3, figsize=(9,16))\n",
    "ax[0,0].imshow(j2ks[1])\n",
    "ax[0,0].axis(\"off\")\n",
    "ax[0,1].imshow(tifs[1], vmax=8000)\n",
    "ax[0,1].axis(\"off\")\n",
    "ax[0,2].imshow(tifs_test[1])\n",
    "ax[0,2].axis(\"off\")\n",
    "for i in range(1, 5):\n",
    "    q = int(np.random.uniform(tifs_test.shape[0]))\n",
    "    ax[i,0].imshow(j2ks[q])\n",
    "    ax[i,0].axis(\"off\")\n",
    "    ax[i,1].imshow(tifs[q], vmax=5000)\n",
    "    ax[i,1].axis(\"off\")\n",
    "    ax[i,2].imshow(tifs_test[q])\n",
    "    ax[i,2].axis(\"off\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T02:04:26.421265Z",
     "iopub.status.busy": "2022-03-03T02:04:26.420915Z",
     "iopub.status.idle": "2022-03-03T02:04:30.172746Z",
     "shell.execute_reply": "2022-03-03T02:04:30.171749Z",
     "shell.execute_reply.started": "2022-03-03T02:04:26.421233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find tifs which need to be interpolated\n",
    "idxs_keep = np.argwhere(np.sum(np.sum(tifs==65535, axis=1), axis=1) != 0).reshape(-1)\n",
    "\n",
    "# tifs_test contains only the bad tifs\n",
    "# idxs_keep contains only the indices of the bad tifs\n",
    "\n",
    "for i in range(idxs_keep.shape[0]):\n",
    "    third_quartile = np.percentile(tifs[idxs_keep[i]][tifs[idxs_keep[i]] != 65535], 75) \n",
    "    first_quartile = np.percentile(tifs[idxs_keep[i]][tifs[idxs_keep[i]] != 65535], 25) \n",
    "    iqr = third_quartile - first_quartile\n",
    "    fence = third_quartile + 1.5 * iqr\n",
    "    \n",
    "    # First, interpolating all pixels other than the NaNs that are considered statistical outliers \n",
    "    fence_condition = tifs[idxs_keep[i]] >= fence\n",
    "    tifs[idxs_keep[i]][fence_condition] = tifs_test[i][fence_condition]\n",
    "    \n",
    "    # Interpolating the NaNs\n",
    "    nan_condition = tifs[idxs_keep[i]] == 65535\n",
    "    tifs[idxs_keep[i]][nan_condition] = tifs_test[i][nan_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T02:05:20.931403Z",
     "iopub.status.busy": "2022-03-03T02:05:20.931065Z",
     "iopub.status.idle": "2022-03-03T02:05:23.800124Z",
     "shell.execute_reply": "2022-03-03T02:05:23.799055Z",
     "shell.execute_reply.started": "2022-03-03T02:05:20.931371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show a random example of an interpolated tif file\n",
    "q = idxs_keep[int(np.random.uniform(idxs_keep.shape[0]))]\n",
    "plt.imshow(tifs[q])\n",
    "plt.show()\n",
    "plt.imshow(j2ks[q])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T02:05:47.06074Z",
     "iopub.status.busy": "2022-03-03T02:05:47.06002Z",
     "iopub.status.idle": "2022-03-03T02:05:48.408081Z",
     "shell.execute_reply": "2022-03-03T02:05:48.407026Z",
     "shell.execute_reply.started": "2022-03-03T02:05:47.060701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the new tifs\n",
    "pickle.dump(tifs, open(\"new_tifs.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T04:09:59.300545Z",
     "iopub.status.busy": "2022-03-02T04:09:59.299979Z",
     "iopub.status.idle": "2022-03-02T04:09:59.305578Z",
     "shell.execute_reply": "2022-03-02T04:09:59.304749Z",
     "shell.execute_reply.started": "2022-03-02T04:09:59.300507Z"
    }
   },
   "source": [
    "## Calculate Metrics\n",
    "\n",
    "Here are the results for the U-Net model:\n",
    "\n",
    "**Train $R^2$:** 0.9264\n",
    "\n",
    "**Validation $R^2$:**   0.8655 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T04:05:53.18132Z",
     "iopub.status.busy": "2022-03-02T04:05:53.181018Z",
     "iopub.status.idle": "2022-03-02T04:05:56.57682Z",
     "shell.execute_reply": "2022-03-02T04:05:56.576012Z",
     "shell.execute_reply.started": "2022-03-02T04:05:53.181268Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the R^2 metric for the U-Net model for both the train and validation sets\n",
    "pred = model.predict(X_v).reshape(X_v.shape[0], 256, 256)\n",
    "x_pred = model.predict(X_t).reshape(X_t.shape[0], 256, 256)\n",
    "R2 = 1 - np.sum((y_v - pred)**2)/np.sum((y_v - np.mean(y_v))**2)\n",
    "print(R2)\n",
    "\n",
    "R2_train = 1 - np.sum((y_t - x_pred)**2)/np.sum((y_t - np.mean(y_t))**2)\n",
    "print(R2_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
