{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Model\n",
    "\n",
    "**Authors:** Jai Sharma, Christopher Sun, Milind Maiti\n",
    "\n",
    "**Date:** 2022.06.16\n",
    "\n",
    "**Description:** This module defines an Autoencoder Deep Learning model for the research paper titled \"A Deep Learning Ensemble Framework for Off-Nadir Geocentric Pose Prediction.\" The tasks here include:\n",
    "\n",
    "1. Define an encoder Deep Learning network which can map a satellite image (from the IEEE dataport) to an embedding of a predetermined size (512).\n",
    "2. Define a decoder Deep Learning network which can map an embedding to an image with the same dimensions as the mentioned satellite images.\n",
    "3. Create a Sequential Keras model which connects the encoder and decoder networks into one autoencoder network with a goal of recovering the original satellite image after creating an embedding.\n",
    "4. Visualize the robustness of the autoencoder model, as explained in number (3).\n",
    "5. Use Multidimensional Scaling (MDS) to visualize the embeddings of the encoder model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-07T01:30:27.72506Z",
     "iopub.status.busy": "2022-04-07T01:30:27.724728Z",
     "iopub.status.idle": "2022-04-07T01:30:33.515875Z",
     "shell.execute_reply": "2022-04-07T01:30:33.515142Z",
     "shell.execute_reply.started": "2022-04-07T01:30:27.724984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.manifold import MDS\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Print Confirmation\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T01:31:59.540501Z",
     "iopub.status.busy": "2022-04-07T01:31:59.539958Z",
     "iopub.status.idle": "2022-04-07T01:32:10.393842Z",
     "shell.execute_reply": "2022-04-07T01:32:10.393147Z",
     "shell.execute_reply.started": "2022-04-07T01:31:59.540463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Data\n",
    "imgs = pickle.load(open(\"/kaggle/input/geocentric-pose-analysis-of-satellite-imagery/j2k_imgs.dat\", \"rb\"))\n",
    "y = pickle.load(open(\"/kaggle/input/geocentric-pose-analysis-of-satellite-imagery/y.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-07T01:32:11.899343Z",
     "iopub.status.busy": "2022-04-07T01:32:11.898992Z",
     "iopub.status.idle": "2022-04-07T01:32:14.700546Z",
     "shell.execute_reply": "2022-04-07T01:32:14.699859Z",
     "shell.execute_reply.started": "2022-04-07T01:32:11.899304Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN Autoencoder\n",
    "# Encoder\n",
    "dim = 512\n",
    "input_img = keras.Input(shape=imgs.shape[1:])\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "shape = x.shape\n",
    "encoded = Dense(dim)(x)\n",
    "encoder = Model(inputs=input_img, \n",
    "                outputs=encoded)\n",
    "\n",
    "# Decoder\n",
    "encoded_input_img = keras.Input(shape=(dim))\n",
    "x = Dense(shape[1])(encoded_input_img)\n",
    "x = Reshape((int(shape[1]**0.5/4),int(shape[1]**0.5/4),16))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
    "decoder = Model(inputs=encoded_input_img,\n",
    "               outputs=decoded)\n",
    "\n",
    "# AutoEncoder\n",
    "autoencoder = Sequential([encoder, decoder])\n",
    "autoencoder.compile(optimizer='adam', loss='mae', metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the encoder model architecture summary\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the decoder model architecture summary\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the autoencoder model architecture summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T05:37:21.605719Z",
     "iopub.status.busy": "2022-03-05T05:37:21.604991Z",
     "iopub.status.idle": "2022-03-05T07:18:30.91476Z",
     "shell.execute_reply": "2022-03-05T07:18:30.91347Z",
     "shell.execute_reply.started": "2022-03-05T05:37:21.60567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Autoencoder\n",
    "history = autoencoder.fit(imgs, imgs, epochs=1000, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-04T10:27:03.577358Z",
     "iopub.status.busy": "2022-03-04T10:27:03.577047Z",
     "iopub.status.idle": "2022-03-04T10:27:03.718175Z",
     "shell.execute_reply": "2022-03-04T10:27:03.717174Z",
     "shell.execute_reply.started": "2022-03-04T10:27:03.577326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Autoencoder weights\n",
    "autoencoder.save_weights(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T07:35:10.208376Z",
     "iopub.status.busy": "2022-03-05T07:35:10.208093Z",
     "iopub.status.idle": "2022-03-05T07:35:14.2364Z",
     "shell.execute_reply": "2022-03-05T07:35:14.235582Z",
     "shell.execute_reply.started": "2022-03-05T07:35:10.208346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode the first 1000 images and get the decodings\n",
    "encoded_imgs = autoencoder.layers[0].predict(imgs[:1000], batch_size=16)\n",
    "decoded_imgs = autoencoder.predict(imgs[:1000], batch_size=16).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Robustness of Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T07:35:15.306077Z",
     "iopub.status.busy": "2022-03-05T07:35:15.305527Z",
     "iopub.status.idle": "2022-03-05T07:35:16.204878Z",
     "shell.execute_reply": "2022-03-05T07:35:16.204267Z",
     "shell.execute_reply.started": "2022-03-05T07:35:15.306036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize robustness of Autoencoder model\n",
    "\n",
    "n = 10  # Number of images displayed\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(imgs[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction image\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(256, 256, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Autoencoder Embeddings using Multidimensional Scaling (MDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:27:34.568751Z",
     "iopub.status.busy": "2022-03-05T08:27:34.56828Z",
     "iopub.status.idle": "2022-03-05T08:28:00.913574Z",
     "shell.execute_reply": "2022-03-05T08:28:00.910724Z",
     "shell.execute_reply.started": "2022-03-05T08:27:34.568712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Color points based on scale\n",
    "colors = y[:,0]\n",
    "embedding = MDS(n_components=2)\n",
    "transformed_imgs = embedding.fit_transform(encoded_imgs)\n",
    "plt.scatter(transformed_imgs[:,0],transformed_imgs[:,1], c=colors[:transformed_imgs.shape[0]], cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-05T08:31:22.98387Z",
     "iopub.status.busy": "2022-03-05T08:31:22.9831Z",
     "iopub.status.idle": "2022-03-05T08:31:23.187681Z",
     "shell.execute_reply": "2022-03-05T08:31:23.186984Z",
     "shell.execute_reply.started": "2022-03-05T08:31:22.983823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Color points based on angle\n",
    "colors = y[:,1]\n",
    "plt.scatter(transformed_imgs[:,0],transformed_imgs[:,1], c=colors[:transformed_imgs.shape[0]], cmap=\"viridis\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
